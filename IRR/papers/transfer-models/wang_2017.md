**summary**
* Propose a baseline deep CNN architecture for practical TSC
* Experiments + analysis on this model
* Many existing methods use distance-based feature extraction + nearest neighbour classification
* They run experiments on an MLP, FCN, and ResNet
* They use a 'less biased' evaluation metric _MPCE_ that seems to normalize dataset error by number of classes, and then get the average of that normalized error over all datasets. I feel like the actual expected error should normalize using class probabilities rather than uniform class distribution. Actually this might just be the error itself ... I guess it's kind of like macro F1 then?
* They find FCN performs the best, _just_ scraping past COTE. 
* ResNet also performs well but tends to overfit, they say.
* They plot representations of different genres of classifier using PCA and note that genres cluster


**FCN model traits**
* GAP layer enables CAM interpretation
* FCN as feature extractor
* FCN is quite basic: just convolutions, batchnorm, and relus for each block. then GAP + softmax to classify
* ResNet is similar but just way more blocks + residual connections